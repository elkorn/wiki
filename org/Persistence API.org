#+FILETAGS: :vimwiki:

* Persistence API
** Akka persistence
# %toc

*** Recover app state after a crash
*** opt-in at-least-once delivery
*** semantics between actors

To add as a dependency:
#+begin_example
"com.typesafe.akka" %% "akka-persistence-experimental" % "2.3.0"
#+end_example

It's a complete rewrite of the [[https://github.com/eligosource/eventsourced][Eventsourced]] library, a migration is possible.

*** Storing state transitions

Instead of storing state, transitions are being recorded.
E.g.
#+begin_example
Cart created => Added 2 socks => Added 2 shirts => Shipping info Added
#+end_example

The events can be replayed and they are immutable (a parallel with DB migration
incremental scripts?).
This is called _event sourcing_.

*** Domain events
**** things that have completed, _facts_
**** immutable
**** verbs in past tense
       - `CustomerRelocated`
       - `CargoShipped`
       - `InvoiceSent`
**** essential building block in DDD, representing the domain state transition.

*Benefits*:
**** Bulletproof auditing and historical tracing.
       - Think in terms of the history of transactions that caused a specific bank account balance to occur.
**** Support future ways of looking at data.
       - After adding new features, it is possible to recreate the past data in the new form.
       - Useful when creating an initial release and then, after discussing with the business, having to add new features and emulate the same state.
**** Performance and scalability
       - Streams can be scaled.
**** Testability
       - Define a sequence of events as a scenario - it makes expected actions very clear.
**** Reconstruct production scenarios
**** No object-relational impedance mismatch
       - No complex data structures are stored, no ORMs needed.
**** Nice fit with actors
       - It does not mean that it should be used everywhere alongside Akka.
       - It's not good for ad-hoc queries.

*** Different approaches

*Command sourcing*:
**** write-ahead-log
**** same behavior during recovery as normal operation
       - external interaction can be problematic
       - changing the command logic will cause retro steps to work as the new cmds
**** persisted before validation
**** allows retroactive changes to the business logic
**** naming: represent intent, imperative

*Event sourcing:*
**** derive events from a Command
**** only state-changing behavior during recovery
**** events cannot fail
**** fixing the business logic will not affect persisted models
**** naming: things that have completed, verbs in the past tense

*** Consistency boundary
**** An actor is a consistency boundary
       - corresponds to a DDD Aggregate
**** No distributed transactions
       - eventually consistent
       - compensating actions instead of transactional mechanisms

*** Building blocks
**** Processor

***** Automatic recovery on start and restart
***** Stashing until recovery completed
***** Failure handling with the supervisor strategy
***** Might want to delete erroneous messages

Minimal processor example
#+begin_example
import akka.persistence.{ Persistent, Processor }
class MyProcessor extends Processor {
    def receive = {
        case Persistent(payload, sequenceNr) =>
            // msg successfully written to Journal
        case other => // msg not written to journal
    }
}

val processor = context.actorOf(Props[MyProcessor], name = "myProcessor")

processor ! Persistent("foo")   // journaled
processor ! "bar"               // not journaled
#+end_example

Real-world example:
#+begin_example

class InvoiceService extends Processor {
    var invoices = Map.empty[String, Invoice]

    def receive: Receive = {
        case Persistent(CreateInvoice(id), _) =>
            invoices = invoices.updated(id, Invoice(id))
        case Persistent(AddInvoiceItem(id, item), _) =>
            invoices.get(id) match {
                case Some(inv) =>
                    invoices = invoices.updated(id, inv.addItem(item))
                case None => // TODO recovery
            }
        case GetInvoice(id) =>
            sender() ! invoices.getOrElse(id, "not found: " + id) ===

        case Persistent(SendInvoiceTo(id, address), _) =>
            // TODO send to the invoice printing service.
    }
}
#+end_example

Invoice context code:
#+begin_example
case class CreateInvoice(invoiceId: String)
case class AddInvoiceItem(invoiceId: String, invoiceItem: InvoiceItem)
case class SendInvoiceTo(invoiceId: String, to: InvoiceAddress)
case class GetInvoice(invoiceId: String)

case class Invoice(id: String, items: IndexedSeq[InvoiceItem] = Vector.empty) {
    def addItem(item: InvoiceItem): Invoice = copy(items = items :+ item)
}

case class InvoiceItem(description: String, count: Int, amount: BigDecimal)
case class InvoiceAddress(name: String, street: String, city: String)
#+end_example

Processor identifier - the default identifier is the path of the actor:
`/user/top/myProcessor`.

Anonymous processors should not be used as the names may change on system
startup.
#+begin_example
    override def processorId = "my-stable-processor-id"
#+end_example

***** Processor with Channel
Handshaking - sending delivery and confirmation messages.
#+begin_example
val printingChannel = context.actorOf(Channel.props(), name = "printingChannel")
val printingDestination = context.system / "printingService"
// 'printingService' probably should be 'printingChannel'.

def receive: Receive = {
    case p @ Persistent(SendInvoiceTo(id, address), _) => 
        // send to the invoice printing machine
        invoices.get(id) match {
            case Some(inv) =>
                printingChannel ! Deliver(p.withPayload(
                    PrintingOrder(inv, address), printingDestination)
                invoices -= inv.id
            case None => TODO
        }
}

class PrintingService extends Actor {
    def receive = {
        case p @ ConfirmablePersistent(payload, sequenceNr, redeliveries) =>
            // ...
            p.confirm()
    }
}
#+end_example

**** Eventsourced processor
Incoming messages (commands) are not persisted.

Steps:
***** Validate Command
***** Create domain event and explicitly persist it
***** Update internal state by *applying the event*
***** External side effects

During recovery the internal state is updated by applying the events, which
prevents any external side effects.

Example:
#+begin_example
class BlogPost extends EventsourcedProcessor {
    import BlogPost._
    override def receiveCommand: Receive = ???
    override def receiveRecover: Receive = ???

    private var state = State("","","",false)

    override def receiveCommand: Receive = {
        case AddPost(author, title) =>
            // The difference between command and event approaches is clear here
            if(state.body == "" && author != "" && title != "") {
                persist(PostAdded(author, title)) { evt =>
                    state = state.updated(evt)
                }
            }

        case ChangeBody(body) =>
            if(!state.published) {
                persist(BodyChanged(body)) { evt =>
                    state = state.updated(evt)
                }
            }

        case Publish =>
            if(!state.published) {
                persist(PostPublished) { evt =>
                    state = state.updated(evt)
                    // call the external web content service...
                }
            }
    }

    override def receiveRecover: Receive = {
        case evt: Event => state = state.updated(evt)
    }
}

object BlogPost {
    import BlogPost._
    case class AddPost(athor: String, title: String) // domain command

    // this is the proposed way:
    sealed trait Event
    case class PostAdded(author: String, title: String) extends Event
    case class BodyChanged(body: String) extends Event
    case object PostPublished extends Event

    private class State(author: String, title: String, body: String,
                        published: Boolean) {
        def updated(evt: Event): State = evt match {
            case PostAdded(author, title)   => copy(author, title)
            case BodyChanged(b)             => copy(body = b)
            case PostPublished              => copy(published = true)
        }
    }
}
#+end_example

Additional functionality: support for snapshots.

#+begin_example
class MyProcessor extends Processor {
    var state: Any = _

    def receive = {
        case "snap"                                   => saveSnapshot(state)
        case SaveSnapshotSuccess(metadata)            => // ...
        case SaveSnapshotFailure(metadata, reason)    => // ...

        case SnapshotOffer(metadata, offeredSnapshot) => state = offeredSnapshot
        case Persistent(payload, _)                   => // ...
    }
}
#+end_example

**** View
Replays persistent messages from a Processor's journal.
Serves as the query side of CQRS.

Features:
***** auto-update interval,
***** update message,
***** limit,
***** may store its own snapshots.

Example:
#+begin_example
class InvoiceCounter extends View {
    import InvoiceCounter._
    override def processorId: String = "/user/InvoiceService"
    override def autoUpdateInterval = 10 seconds

    var count = 0L

    def receive: Actor.Receive = {
        case Persistent(payload: SendInvoiceTo, _) => count += 1
        case _: Persistent =>
        case GetInvoiceCount => sender ! InvoiceCount(count)
    }
}

object InvoiceCounter {
    case object GetInvoiceCount
    case class InvoiceCount(count: Long)
}
#+end_example

**** Persistent Channel
Used for at-least-once delivery.

A message might be dropped.
To be sure that a message has arrived, an acknowledgment from the receiver.
The acknowledgment delivery may also fail - in that case the message must be
resent.
This is the _at-least-once_ delivery mode.

Channels re-deliver messages until confirmed.
The confirmation is on application level.
Different semantics:
***** duplicates received
***** message order not retained
***** after a creash and restart messages are still delivered

Recommendation: use one destination per channel.
The exception is when replies are being sent via the channel.

Where a Channel is meant to be used from within a Processor and resides within
memory, the PersistentChannel is to be used standalone.

It is conceptually a processor + a channel.
It persists messages before delivering, replies `ack` when persisted and allows
more advanced delivery flow control.

Example:
#+begin_example
class MyProcessor extends Processor {
    val channel = context.actorOf(Channel.props(), name = "myChannel")

    def receive = {
        case p @ Persistent(payload, _) =>
            val destination = context.system / "myDestination"
            channel ! Deliver(p.withPayload("output msg"), destination)
    }
}

class MyDestination extends Actor {
    def receive = {
        case p @ ConfirmablePersistent(payload, sequenceNr, redeliveries) =>
            // ...
            p.confirm()
    }
}

class Endpoint extends Actor {
    val channel = context.actorOf(
            PersistentChannel.props(PersistentChannelSettings(
                    redeliverInterval = 3 seconds,
                    redeliverMax = 10,
                    replyPersistent = true)
            ),
            name = "myChannel")
    val destination = context.system / "jobManager"

    import context.dispatcher
    implicit val timeout = Timeout(5 seconds)

    def receive = {
        case job: Job =>
            (channel ? Deliver(Persistent(job), destination)) map {
                // send the acknowledgment
                case _: Persistent => "OK: " + job.id
            } recover {
                case e => "FAILED: " + job.id
            } pipeTo sender()
    }
}
#+end_example

**** Serialization
***** Pluggable, Akka serialization
***** app life-cycle, versioning
***** don't use default Java serialization

***** Journal
****** Pluggable
****** LevelDB shipped with Akka - local files
****** [[http://akka.io/community/][Community journals]] can be used

**** Cluster
***** simple way of migrating/moving stateful actors in a cluster
***** distributed journal
        - shared LevelDB journal for testing
        - try the Cassandra alternative
***** single write per event stream

***** Cluster singleton
Follow-up...

***** Cluster sharding
Follow-up...

Send the recipient identifier with a message to a cluster sharding region.

A routing coordinator is required.

#+begin_example
val idExtractor: ShardRegion.IdExtractor = {
    case cmd: Command => (cmd.postId, cmd)
}

val shardResolver: ShardRegion.ShardResolver = msg => msg match {
    case cmd: Command => (math.abs(cmd.postId.hashCode) % 100).toString
}

ClusterSharding(system).start(
    typeName = BlogPost.shardName,
    entryProps = Some(BlogPost.props()),
    idExtractor = BlogPost.idExtractor,
    shardResolver = BlogPost.ShardResolver)

val postRegion: ActorRef =
    ClusterSharding(context.system).shardRegion(BlogPost.shardName)

val postId = UUID.randomUUID().toString
postRegion ! BlogPost.AddPost(postId, author, title)
#+end_example
