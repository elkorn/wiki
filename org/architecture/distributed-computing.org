* DistributedComputing
** Fallacies of distributed computing

There exist 8 main assumptions about distributed systems which architects tend to make,
that prove wrong in the long run.

**** The network is reliable
***** Reason
We are not talking only about hitting the failure described in a switch's MTBF statement,
when your application is a 365x7, mission critical type of software.

There are plenty of problems.
****** Power failures,
****** Someone tripson the network cord,
****** All of a sudden clients connect wirelessly,
****** If the hardware does not fail - the software can.

This is an issue especially when working with 3rd parties (think: payment systems,
external services), since you don't really ahve any control over the behavior or
connection to the given 3rd party.

Lastly, there are cases of attacks such as DDOS.

The network is *unreliable* and that software architects have to take that into account.

***** Solutions

You need to think about hardware and software redundancy and weigh the risks of failure
vs. the required investments.
Things tend to stop being binary or absolute, everything rather becomess characterized
by specific sets of tradeoffs.

On the software side, you need to think about messages being lost whenever communicating
over the network.

You need to start thinking about tools providing message delivery guarantees and which 
of those guarantees is the most applicable to your case (e.g. at-least-once delivery,
at-most-once delivery, exactly-once delivery, in-order, out-of-order...), because each 
one comes with different performance characteristics and functional tradeoffs.
Think about retrying, acknowledging messages, coping with duplicates (idempotency of
messages), reordering messages, integrity of messages etc.

**** Latency is zero
***** Reason
Latency is how much time it takse for data to move between places.
This is opposed to bandwidth, which describes *how much* data can be transferred in
given time.

Latency can be good on LAN - but that's pretty much it. It's non-negligible everywhere
else.

Latency is more problematic than bandwidth.
Within the last 11 years, bandwidth has increased 1468x, while latency only 10x.
Furthermore, there exists a natural boundary for latency.
The minimum round-trip time between two points on earth is determined by speed of light.
It will always take at least 30ms to send a ping from Europe to the US and back even if
the processing would be done in real time.

Beware of constructs that provide "network transparency" - such as distributed objects.
Network communication is by nature latent and asynchronous.
There is no way around that at this time.

***** Solutions

Make as few calls as possible and try to move as much data per call as possible.
This serves to reduce the share of round-trip time in the request-response cycle.

You should test application's reaction to latency.
Real world conditions should be emulated in test environments so that reliable results
can be achieved.

**** Bandwidth is infinite
***** Reason

This is not a very strong fallacy - bandwidth is getting much better with time.

The balancing forces though are as follows:
****** While bandwidth grows, so does the amount of information we try to squeeze through it (think terabytes of data a day!).
****** The smaller the frame size, the larger the packet loss.
         - To achieve 500 Mbps with 9000 byte frames, we need a packet loss rate of $\leq 1*10^(-5)$
         - To achieve 500 Mbps with 1500 byte frames, we need a packet loss rate of $\leq 2.8*10^(-7)$

***** Solutions

Strive to limit the information sent over the wire.

Consider that in the production environment there may be bandwidth problems out of your
control.
Bear in mind how much data is expected to travel over the wire.

**** The network is secure
***** Reason

Even if your application is secure, there are no guarantees that any 3rd party code that
you happen to use or interact with also is.

Additionally, there comes network security.
Over 50% of chief security officers admit to having a "Moat & Castle" approach to
security i.e. once the perimeter has been breached, there is mostly nothing to stop an
attacker.

Use of automated attack tools is so widespread that attack metric providers have started
to work on a more meaningful metric than just "incidents".

***** Solutions

Security is a process that has to be taken into account *from day 1*.
It is a system quality attribute that has to be taken into account starting from the 
architectural level.

Security is also a vast topic that is hard to summarize properly in a paragraph.
Threat modelling has to be performed to evaluate risks and after following analysis, 
decisions have to be made which ones should be mitigated by what measures.
As with most things, there are tradeoffs between mitigation costs and risk probability.
Security can be implemented on multiple layers, from infratstructure, to applications.

As an architect, not being a security expert does not relieve you from being aware of the
need for it as well as the implications it, as well as the lack of it, may have.
Example implications:
****** you might not be able to use multicast due to security concerns,
****** user accounts with limited privileges might not be able to access some networked resource.

**** Topology does not change
***** Reason

Deploying an application to an organization, the network topology is usually beyond your
control.
The operations team may add or remove servers or make changes to the networks (change
protocols, rewire a subnet etc.)

With clients, the situtation is more extreme - there are laptops, ad-hoc networks and
wireless mobile devices.
Topology is changing *constantly*.

***** Solutions

Do not depend on specific endpoints or routes, if you cannot be prepared to renegotiate
endpoints.

Also, you would want to be able to either provide location transparency (using a service 
bus) or provide discovery services.

Another strategy would be to abstract the physical structure of the network.
The most obvious step would be to favor DNS names instead of IP addresses.

*WS-Routing vs WS-Addressing*

In WS-Routing, a message describes its own path - meaning that it is assumed to know the
path in advance.
WS-Addressing relies on "Next Hop" routing (as does TCP/IP), meaning its more robust.

Also, routing in SQL Server Service Broker is problematic - whenever topology changes, the
IT department has to go into the SQLSSB and update the routing tables.

**** There is one administrator
***** Reason

This fallacy may not apply to small, isolated LANs and similar networks.

Enterprises have usually different administrators assigned to parts of the system based
on their expertise - databases, web servers, networks, Windows, Linux, Mainframe etc.

Problems occur when the company cooperates with xternal entities or if an application is
deployed for Internet consumption and hosted by an external hosting service or consuming
external services.
In these situations, the administrators of those services are not under your control.

If everything goes well, you might not even have to care.
You most definitely do, when things are starting to go wrong.

***** Solutions
Provide administrators with tools to diagnose and find problems, especially if the
application involves more than one company ("whose problem is that?").

Proactively, include tools for monitoring ongoing operations as well e.g. to allow admins
to identify problems when they are small - before they become a system failure.

Express iteroperability in contracts.
This is very important when it comes to updating parts of the system, even more so when
operating with 3rd parties. 
Pieces of the system as well as its partners should be able to interop with it regardless
of what state parts of the system are.
Be aware of that and keep in mind backward compatibility and maybe even forward
compatibility.

Remember also that each administrator may constrain your options (e.g. set disk quotas,
limit privileges, limit ports and protocols etc.) due to their specific needs.

**** Transport cost is zero
***** Reason

One way to interpret this is that going from application level to the transport level 
(think OSI/ISO stack) is free.
This is false, since marshalling has to be done to get data onto the wire - that adds to
latency and takes up computer resources (this pertains to the "Latency is zero" fallacy).

Another way of interpretation is that the costs (as in $$$) for setting and running the
network are zero.
The infrastructure has to be bought, the bandwidth for Internet connections has to be
leased, operating and maintaining the network running is not free either.
Someone, somewhere will have to pay for all this.

***** Solution

It might be sensible to take into account when preparing projections of the project's
financial impact.

Even if you managed to build an incredible, disruptive new service - neglecting the costs 
that are required to set it up, host it or run it will cause you to fail.

Remember also that even if other fallacies do not apply to your situation, this one most
likely will anyway.

**** The network is homogenous
***** Reason

It is naive to assume that a network consists solely of devices of one type, communicating
in the same way with each other.

Assumng this fallacy would not cause too much serious trouble at the lower network level 
since IP is quite ubiquitous - it may result in suboptimal use of the non-native IP
resources.

***** Solutions

Pay attention to the fact that the network is not homogenous at the application level.
The implications is that you have to assume interoperability will be needed sooner or
later and be ready to support it from Day 1 or a least design where you'd add it later.

Reliance on proprietary protocols is not advised, as integration of those is harder.
It's better to use standard, open technologies that are widely recognized and accepted.
The most notable of course are XML, Web Services, HTTP, JSON.

** Distributed system checklist

The following list gives a better idea of what should be considered when designing a distributed system.

*** Fault tolerance
**** What happens when a dependency starts failing? What if it begins failing *slowly*?
**** How can the system *degrade* in a graceful manner?
**** How does the system react to overload? Is it well-conditioned? (i.e. does it cope well with increased load?)
**** What's the worst-case scenario for total failure?
**** How quickly can the system recover?
**** Is delayable work delayed?
**** Is the system as *simple* as possible? Why cannot it be simpler?
**** How can the system shed load?
**** Which failures can be mitigated and how?
**** Which operations may be retried? Are they being retried?

*** Scalability
**** How does the system grow? What is the main metric with which the system scales?
**** How does the system scale to multiple datacenters?
**** How does demand vary?
**** How do you ensure the system is always able to handle peak loads?
**** How much query processing is done? Can data be shaped into queries?
**** Is the system replicated?

*** Operability
**** How can features be turned on or off?
**** How do you monitor the system? How are anomalies detected?
**** Does the system have operational needs specific to the application?
**** How is the system deployed? How is it deployed in an emergency situation?
**** What are the capacity needs? How does the system grow?
**** How do you configure the system? How do you do it *quickly*?
**** Does the system behave in a predictable manner? Are there nonlinearities in load or failure response? If so, where?

*** Efficiency
**** Is it possible to precompute data?
**** Are you doing as little work as possible?
**** Is the program as concurrent as possible?
**** Does the system make use of work batching?
**** Have you profiled the sustem? Is it possible to profile on site?
**** Can you load test the system? How do you catch performance regressions?
** Distributed computing - harvest and yield

Any distributed system will experience enough faults that it will have to make a choice between reducing yield (i.e. stop answering requests) and reducing harvest (i.e. giving answers based on incomplete data) - such decisions should be based on business requirements.

Fact of the matter is that most often failures of consistency are tolerated or even expected, but just about every failure of availability means lost money.
The choice of availability over consistency is at its core a business choice, not a technical one.
Examples of availability failure consequences:

- failed google search == fewer ads served and advertisers charged,
- an item that cannot be added to a basket == fewer items sold,
- an unprocessed credit charge == regulatory fine.

*** Harvest

Harvest is the ratio of the amount of data available to the total amount of data in the system.

Given we have three nodes =A=,=B= and =C=, containing indexes of web pages containing the following search terms:

- =A=: "cute"
- =B=: "baby"
- =C=: "animals"

a search for "cute baby animals", combining results from all nodes, would have a 100% harvest.
If node =B= was unavailable, the system might return the result for "cute animales"

*** Yield

Numerically, yield is typically close to uptime.
However, it is more useful in practice - it maps directly to user experience.
Yield correctly reflects the fact that not all esconds have equal value.
A second of downtime during a period when no queries are being made has no impact on yield.
That same second of downtime during peak and off-peak times generates the same uptime but a vastly different yield value.
