= Go concurrency patterns =
%toc

(from http://blog.golang.org/pipelines )

Go's concurrency primitives lead to constructing streaming data pipelines.

A pipeline is a series of *stages* cnnected by channels, where each stage is a group of
goroutines running the same function.

In each stage, the goroutines:
- receive values from upstream via inbound channels,
- perform some function on that data,
- send values downstream via outbound channels.

(There is a strong analogy with node.js streams here.)

Each stage has any number of channels, except the first and the last one - which have
only inbound and outbound, respectively.

The first stage is called the _source_ or _producer_, the last stage- a _sink_ or _consumer_.
(Parallel to general concurrent programming terms here)

== Squaring numbers ==
_Consumer_ stage: `gen`

{{{
func gen(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        for _, n := range nums {
            out <- n
        }
        close(out)
    }()
    return out
}
}}}

_Worker_ stage: `sq`

{{{
func sq(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        for n := range in {
            out <- n * n
        }
        close(out)
    }()
    return out
}
}}}

_Producer_ stage: `main`
{{{
func main() {
    // Set up the pipeline.
    c := gen(2, 3)
    out := sq(c)

    // Consume the output.
    fmt.Println(<-out) // 4
    fmt.Println(<-out) // 9
}
}}}

Note that the input and output channel of `sq` have the same type.
This makes it composable any number of times.

== Fan-out, fan-in ==

*Fan-out* means that multiple functions may read from the same channel until it's
closed.
Due to this, work can be distributed amongst workers to parallelize CPU use and I/O.

*Fan-in* means multiplexing multiple input channels onto a single output channel which
is closed after all inputs are closed.

We can translate the `sq` pipeline to run two instances.
{{{
func main() {
    in := gen(2, 3)

    // Distribute the sq work across two goroutines that both read from in.
    c1 := sq(in)
    c2 := sq(in)

    // Consume the merged output from c1 and c2.
    for n := range merge(c1, c2) {
        fmt.Println(n) // 4 then 9, or 9 then 4
    }
}
}}}

`merge` converts multiple channels into one, by starting a goroutine for each one and
copying their values to the output.
After all inputs are closed, an additional goroutine is started to close the outbound
channel after everything is sent.
{{{
func merge(cs ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int)

    // Start an output goroutine for each input channel in cs.  output
    // copies values from c to out until c is closed, then calls wg.Done.
    output := func(c <-chan int) {
        for n := range c {
            out <- n
        }
        wg.Done()
    }
    wg.Add(len(cs))
    for _, c := range cs {
        go output(c)
    }

    // Start a goroutine to close out once all the output goroutines are
    // done.  This must start after the wg.Add call.
    go func() {
        wg.Wait()
        close(out)
    }()
    return out
}
}}}

`sync.WaitGroup` acts as a barrier.
Sending anything to a closed channel causes a panic, so the barrier takes care of that.

== Stopping short ==

Having given the following:
- stages close outbound channels when all send operations are done,
- stages keep receiving from inbound channels until they're closed,

one can write a channel interaction as `range`.

In reality though, stages do not always act like that.
Sometimes the receiver may only need a subset of values to proceed.
More often, there is an error in one of the early stages that causes it to exit early.

The receiver should not have to wait for _all_ the values to arrive and we should be
able to make the earlier stages stop producing values that later stages do not need.

In the pipeline created earlier, blocked goroutines will stay around forever, causing a
resource leak.

One way to avoid such a situation is to change the outbound channels to their buffered
counterparts.
This alows for some simplifications:
{{{
func gen(nums ...int) <-chan int {
    out := make(chan int, len(nums))
    for _, n := range nums {
        out <- n
    }
    close(out)
    return out
}

func merge(cs ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int, 1) // enough space for the unread inputs
    // ... the rest is unchanged ...
}}}

This is bad code though - the buffer size choice depends on knowing the number of
values `merge` will receive and the downstream stages will consume.
It's obviously fragile.

A better alternative is to have cancellation channels as a way of downstream stages
signalling to the upstream that they no longer need data.
