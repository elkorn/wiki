* API problems
(via http://writings.quilt.org/2014/05/12/distributed-systems-and-the-end-of-the-api/)

The API is considered to be a hold-over from concepts predating distributed
systems.

APIs necessitate actor coupling.
Only two-party client/server architectures are admitted.
There are 7 main topologies: Ring, Mesh, Star, Fully Connected, Line, Tree, Bus.
Yet the API requires these topologies to be pushed into client/server boxes 
(e.g. through tools like queues or service buses).
Arbitrary data is being used.
Clients always need to reconcile with the server how should the data be represented.

APIs are synchronous in nature.
There are some patterns and workarounds, but still they are just that.

APIs do not take into account the fundamental distributed system problems:
- Network failure modes such as latency, disconnection, partitioning, offline contexts,
- Making consistency choices relevant to a given application and being aware of consistency choices being made on our behalf,
- Being aware the impact of made consistency choices,
** How our data models and representations influence/determine possible scenarios of concurrent actor operation.

** Network problems

Not acknowledging the nature of the network (i.e. trying to hide it under some
abstraction) causes its failures to have to be accounted for very explicitly
and often times hurting the performance.
The basic network failure modes:
*** Partitions
*** Latency variations
      - variable latency (overloaded, switches, GC etc.)
      - complete and permanent loss of interconnect
      - offline operation
*** Reordered messages
*** Repeated messages.

A partition between app servers can cause in-memory sessions to diverge 
(use a state server?), leading to incariants being violated on the whole stack.
Increased latency may trip some machines/services within different parts of the
system, leading to spiking reconnect attempts and thus cascading latency.

** Consistency decisions
The set of consistency options is like a multidimensional space as there are a
lot of considerations that go into choosing a set of consistency guarantees.

The most common cases include:
*** Strict linearizability: all actors in the system sync. acknowledge each write to shared data, yielding a global total order of operations. Systems acts as if its state is held in a single atomic reference. Very expensive but intuitive.
*** Causal consistency: logically temporal relationships between dependent changes to shared data are tracked (this is done through logical clocks, acting like temporal state versioning). This yields a partial order of all operations. Much cheaper than strict linearalizability but offers many desirable guarantees as well e.g. to read your own writes. Without a causal cons. mechanism it is possible e.g. for a web client to write a value through an HTTP API and then see the previous value when it performs a read or query some time afterwards.
*** Eventual consistency: concurrent writes converge (with possible conflicts) such that different readers will all eventually see the same result at some point in the future, after all prior writes have been applied. The only guarantee provided here is _liveness_ - all actors within the system will propagate writes until all actors have seen every write.

Choosing a consistency model has a compensating impact on Availability and Partition tolerance (from the CAP theorem).
The basic dynamic tradeoff between consistency and availability:
*** As every actor in a system has to sync. acknowledge each write made by others, then those actors cannot accept any new work until that happens. During this time system will appear to be down (unavailable).
*** If no consesnus is required then any actor can always accept new work. Omitting any other issues that might arise. the system will always be available and responsive to external parties.

An important thing to note that different parts of a system may have different consensus requirements and guarantees may change over time in order to accomodate user expectations and coherence demands of different kinds of data.

Network APIs provide nothing in terms of CAP - nothing is being presumed, apart from a socket being available.

** Possible solutions
The key factors required in a distributed system:
- Communication: the ability to share data among the various actors.
- Computation: the ability to consume and transform data, producing new data as a result that is perfhaps itself communicated.

Two main approaches have been developed:
- Consistency As Logical Monotonicity (CALM theorem), relying upon temporal logic
*** Conflict-free Replicated Data Types (CRDTs), relying upon the algebra of _semilattices_.

They constrain the types of operations that a system can perform in order to ensure convergence over time of changes to data shard by concurrent actors and eliminate network failure modes as source of errors.

CRDTs are included as a banner feature in the impending next release of Riak.

*** CRDTs
A *lattice*:
- partially-ordered set
    - for any two members $\{a, b\}$ there exists
        - a least upper bound 
            - a value "greater than" both members
            - called the _join_ or the _supremum_, denoted as $a \vee b$ 
        - a greatest lower bound 
            - a value that is "less than" both members
            - called the _meet_ or the _infimum_, denoted as $a \wedge b$

A *semilattice*:

- a lattice that admits only the join or the meet
- in another words, it is ordered in only one direction.

If a lattice has an absolute maximum (top) or an absolute minimum (bottom) it is said to be bounded. 

CRDTs are premised upon join semilattices - a "greater than" relationship holds for every member of such a set.

Two examples:

- The- of natural numbers, where the join operation is =max=.
- The set $\{a,b\}$ semilattice with a =union= join operation:

#+begin_example
        {a,b}        / \
       /     \        |
    {a}       {b}     |
   /   \              |
{a}    $\emptyset$    | time
#+end_example

A set semilattice with a join operation of =union= will never lose information - the value of each memeber will always increase in size along with the joins across participants sharing the semilattice.

Join and meet operations for any semilattice must satisfy 3 axiomatic properties:

- Associativity: ability to batch inputs to an operation in any way without affecting the result. =f(f(a,b),c) == f(a, f(b,c))=
- Commutativity: ability to change the order of operation inputs without affecting the result. =f(a,b) == f(b,a)=
- Idempotence: ability to apply an operation multiple times without affecting  the result. =f(f(a)) == f(a)=

As long as these properties hold, the data structure is a semilattice and is sheltered from some of the most problematic network failure modes: reordering and repeating of network messages.

As long as liveness is preserved (most inimal guarantee of eventual consistency) the convergence of concurrent modifications occurs without conflict.
Operations that aim for reducing information over time, however, do not inherently satisfy these axioms.
They key is that only the primitive operations over semilattices and CRDTs must satisfy then; other operations can be implemented in terms of those primitives, thus yielding the desired characteristics.
More details on how this is done can be found in [[http://hal.upmc.fr/file/index/docid/555588/filename/techreport.pdf][the study]].

**** CRDT Data Models
CRDTs have been built to represent a wide range of data types, including:

- counters
- registers
- sets
- (multi)maps
- dense and sprase lists/vectors
- partially-ordered sequences
- trees
- graphs

Semilattices naturally support immutability.
The most naive approach to CRDTs is to keep an immutable log of operations being applied or state being added.
Things like histories, rollbacks, consistent snapshots all come effectively for free.

**** From APIs to CRDTs
Use cases addressable by an API might can be entirely supersetted by using a CRDT.
The transformation is of changing imperative, side-effecting calls as
#+begin_example
api.setName(personId, "Chas");
#+end_example
into reified data that gets added to a CRDT, which is replicated from a "client" to other actors:
#+begin_example
{ :person-id person-id :name "Chas" }
#+end_example

"Operations" being cast to data become computable - they can be copied, routed, reordered, manipulated and having applied programs to them at any level of a system.
This is similar to how event sourcing and message queues are premised - producers and consumers are decoupled and operations are serialized as messages, becoming as pliable as any other data.

CRDT implementations have been generally materialized as libraries, not runtimes/languages.
Other programming models well suited for distributed systems:
***** Event sourcing
***** Stream-based computation (Storm)
***** [[TupleSpaces]] for characterizing scale-invariant concurrent distributed computation
****** TupleSpaces
#= Architecture - tuple spaces =
A tuple space is an implementation of the associative memory paradigm for parallel/distributed computing. It provides a repository of tuples that can be accessed concurrently. As an illustrative example, consider that there are a group of processors that produce pieces of data and a group of processors that use the data. Producers post their data as tuples in the space, and the consumers then retrieve data from the space that match a certain pattern. This is also known as the blackboard metaphor ([[BlackboardSystem]]). Tuple space may be thought as a form of distributed shared memory.

Example (JavaSpaces):
#+begin_example
// An Entry class
public class SpaceEntry implements Entry {
     public final String message = "Hello World!";
     public Integer count = 0;
 
     public String service() {
         ++count;
         return message;
     }
 
     public String toString() {
         return "Count: " + count;
     }
}
// Hello World! server
public class Server {
     public static void main(String[] args) throws Exception {
         SpaceEntry entry = new SpaceEntry();            // Create the Entry object
         JavaSpace space = (JavaSpace)space();           // Create an Object Space
         // Register and write the Entry into the Space
         space.write(entry, null, Lease.FOREVER);        
         // Pause for 10 seconds and then retrieve the Entry and check its state.
         Thread.sleep(10 * 1000);
         SpaceEntry e = space.read(entry, null, Long.MAX_VALUE);
         System.out.println(e);
     }
}
// Client
public class Client {
     public static void main(String[] args) throws Exception {
         JavaSpace space = (JavaSpace) space();
         SpaceEntry e = space.take(new SpaceEntry(), null, Long.MAX_VALUE);
         System.out.println(e.service());
         space.write(e, null, Lease.FOREVER);
     }
}
#+end_example
******* BlackboardSystem
#= Architecture - blackboard system =

A blackboard system is an artificial intelligence application based on the blackboard architectural model, where a common knowledge base, the "blackboard", is iteratively updated by a diverse group of specialist knowledge sources, starting with a problem specification and ending with a solution. Each knowledge source updates the blackboard with a partial solution when its internal constraints match the blackboard state. In this way, the specialists work together to solve the problem. The blackboard model was originally designed as a way to handle complex, ill-defined problems, where the solution is the sum of its parts.


The following scenario provides a simple metaphor that gives some insight into how a blackboard functions:

A group of specialists are seated in a room with a large blackboard. They work as a team to brainstorm a solution to a problem, using the blackboard as the workplace for cooperatively developing the solution.

The session begins when the problem specifications are written onto the blackboard. The specialists all watch the blackboard, looking for an opportunity to apply their expertise to the developing solution. When someone writes something on the blackboard that allows another specialist to apply their expertise, the second specialist records their contribution on the blackboard, hopefully enabling other specialists to then apply their expertise. This process of adding contributions to the blackboard continues until the problem has been solved.
***** Reactive patterns (FRP).

**** Costs
***** All operations must adhere to the semilattice axioms.
***** CRDTs must be used to mediate all interactions between all actors in a distributed system in order to benefit from their advantages.
